{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная работа №5. Построение нейронных сетей для Q-обучения с помощью PyTorch и Tensorflow\n",
        "\n",
        "Горюнов Н.С., гр. 5140201/30301"
      ],
      "metadata": {
        "id": "GWx5SLNYHPqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1 Реализация на PyTorch"
      ],
      "metadata": {
        "id": "OWwDB6cUHnKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "env = gym.make(\"CartPole-v0\").env\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "plt.imshow(env.render(\"rgb_array\"))\n",
        "\n",
        "assert not torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "E-T973TiH55X",
        "outputId": "a8e8ccd4-dbae-41a0-cddf-798bd574f734"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:593: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAF7CAYAAAD4/3BBAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJmJJREFUeJzt3X9w1PWB//FXfu1CCLsxQLJJSRAFgQhBDzDs2Xq0pASInpzxO2o5iD0GRi5xCrEU06MitmM8vDl/9BD+aE+8GSktHdGTCjYGCbWGH6ak/NJUGK7Bkk1QvtlNYglJ9v39wy+fuVVENgT2nfB8zHxmsp/Pe3ffn/cwkye7n93EGWOMAAAALBIf6wkAAAB8HoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArBPTQFm3bp2uv/56DRo0SPn5+dq3b18spwMAACwRs0D55S9/qfLycq1evVp/+MMfNHnyZBUWFqqlpSVWUwIAAJaIi9UfC8zPz9e0adP0H//xH5KkcDis7OxsPfzww3r00UdjMSUAAGCJxFg86blz51RXV6eKigpnX3x8vAoKClRbW/uF8Z2dners7HRuh8NhnTlzRsOGDVNcXNxVmTMAALg8xhi1tbUpKytL8fEXfxMnJoHy8ccfq6enRxkZGRH7MzIy9MEHH3xhfGVlpdasWXO1pgcAAK6gkydPauTIkRcdE5NAiVZFRYXKy8ud28FgUDk5OTp58qQ8Hk8MZwYAAC5VKBRSdna2hg4d+pVjYxIow4cPV0JCgpqbmyP2Nzc3y+fzfWG82+2W2+3+wn6Px0OgAADQz1zK5Rkx+RSPy+XSlClTVF1d7ewLh8Oqrq6W3++PxZQAAIBFYvYWT3l5uUpKSjR16lTddtttevbZZ9XR0aHvfve7sZoSAACwRMwC5b777tPp06f12GOPKRAI6JZbbtGOHTu+cOEsAAC49sTse1AuRygUktfrVTAY5BoUAAD6iWh+f/O3eAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgnT4PlMcff1xxcXER2/jx453jZ8+eVWlpqYYNG6aUlBQVFxerubm5r6cBAAD6sSvyCsrNN9+spqYmZ3vnnXecY8uXL9frr7+uLVu2qKamRqdOndI999xzJaYBAAD6qcQr8qCJifL5fF/YHwwG9fOf/1ybNm3St771LUnSiy++qAkTJmjPnj2aPn36lZgOAADoZ67IKygffvihsrKydMMNN2j+/PlqbGyUJNXV1amrq0sFBQXO2PHjxysnJ0e1tbVf+nidnZ0KhUIRGwAAGLj6PFDy8/O1ceNG7dixQ+vXr9eJEyf0jW98Q21tbQoEAnK5XEpNTY24T0ZGhgKBwJc+ZmVlpbxer7NlZ2f39bQBAIBF+vwtnjlz5jg/5+XlKT8/X6NGjdKvfvUrDR48uFePWVFRofLycud2KBQiUgAAGMCu+MeMU1NTddNNN+nYsWPy+Xw6d+6cWltbI8Y0Nzdf8JqV89xutzweT8QGAAAGriseKO3t7Tp+/LgyMzM1ZcoUJSUlqbq62jne0NCgxsZG+f3+Kz0VAADQT/T5Wzzf//73ddddd2nUqFE6deqUVq9erYSEBD3wwAPyer1atGiRysvLlZaWJo/Ho4cfflh+v59P8AAAAEefB8pHH32kBx54QJ988olGjBihr3/969qzZ49GjBghSXrmmWcUHx+v4uJidXZ2qrCwUC+88EJfTwMAAPRjccYYE+tJRCsUCsnr9SoYDHI9CgAA/UQ0v7/5WzwAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArBN1oOzevVt33XWXsrKyFBcXp1dffTXiuDFGjz32mDIzMzV48GAVFBToww8/jBhz5swZzZ8/Xx6PR6mpqVq0aJHa29sv60QAAMDAEXWgdHR0aPLkyVq3bt0Fj69du1bPP/+8NmzYoL1792rIkCEqLCzU2bNnnTHz58/XkSNHVFVVpW3btmn37t1asmRJ788CAAAMKHHGGNPrO8fFaevWrZo3b56kz149ycrK0iOPPKLvf//7kqRgMKiMjAxt3LhR999/v95//33l5uZq//79mjp1qiRpx44dmjt3rj766CNlZWV95fOGQiF5vV4Fg0F5PJ7eTh8AAFxF0fz+7tNrUE6cOKFAIKCCggJnn9frVX5+vmprayVJtbW1Sk1NdeJEkgoKChQfH6+9e/de8HE7OzsVCoUiNgAAMHD1aaAEAgFJUkZGRsT+jIwM51ggEFB6enrE8cTERKWlpTljPq+yslJer9fZsrOz+3LaAADAMv3iUzwVFRUKBoPOdvLkyVhPCQAAXEF9Gig+n0+S1NzcHLG/ubnZOebz+dTS0hJxvLu7W2fOnHHGfJ7b7ZbH44nYAADAwNWngTJ69Gj5fD5VV1c7+0KhkPbu3Su/3y9J8vv9am1tVV1dnTNm586dCofDys/P78vpAACAfiox2ju0t7fr2LFjzu0TJ06ovr5eaWlpysnJ0bJly/STn/xEY8eO1ejRo/WjH/1IWVlZzid9JkyYoNmzZ2vx4sXasGGDurq6VFZWpvvvv/+SPsEDAAAGvqgD5b333tM3v/lN53Z5ebkkqaSkRBs3btQPfvADdXR0aMmSJWptbdXXv/517dixQ4MGDXLu8/LLL6usrEwzZ85UfHy8iouL9fzzz/fB6QAAgIHgsr4HJVb4HhQAAPqfmH0PCgAAQF8gUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdaIOlN27d+uuu+5SVlaW4uLi9Oqrr0Ycf/DBBxUXFxexzZ49O2LMmTNnNH/+fHk8HqWmpmrRokVqb2+/rBMBAAADR9SB0tHRocmTJ2vdunVfOmb27Nlqampytl/84hcRx+fPn68jR46oqqpK27Zt0+7du7VkyZLoZw8AAAakxGjvMGfOHM2ZM+eiY9xut3w+3wWPvf/++9qxY4f279+vqVOnSpJ++tOfau7cufq3f/s3ZWVlRTslAAAwwFyRa1B27dql9PR0jRs3TkuXLtUnn3ziHKutrVVqaqoTJ5JUUFCg+Ph47d2794KP19nZqVAoFLEBAICBq88DZfbs2fqv//ovVVdX61//9V9VU1OjOXPmqKenR5IUCASUnp4ecZ/ExESlpaUpEAhc8DErKyvl9XqdLTs7u6+nDQAALBL1Wzxf5f7773d+njRpkvLy8nTjjTdq165dmjlzZq8es6KiQuXl5c7tUChEpAAAMIBd8Y8Z33DDDRo+fLiOHTsmSfL5fGppaYkY093drTNnznzpdStut1sejydiAwAAA9cVD5SPPvpIn3zyiTIzMyVJfr9fra2tqqurc8bs3LlT4XBY+fn5V3o6AACgH4j6LZ729nbn1RBJOnHihOrr65WWlqa0tDStWbNGxcXF8vl8On78uH7wgx9ozJgxKiwslCRNmDBBs2fP1uLFi7VhwwZ1dXWprKxM999/P5/gAQAAkqQ4Y4yJ5g67du3SN7/5zS/sLykp0fr16zVv3jwdOHBAra2tysrK0qxZs/TjH/9YGRkZztgzZ86orKxMr7/+uuLj41VcXKznn39eKSkplzSHUCgkr9erYDDI2z0AAPQT0fz+jjpQbECgAADQ/0Tz+5u/xQMAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrRP3HAgHgSjLhsI799gV91V/huLFgsRKSBl2lWQG42ggUAJYxam08LJnwxUeFe67SfADEAm/xAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6UQVKZWWlpk2bpqFDhyo9PV3z5s1TQ0NDxJizZ8+qtLRUw4YNU0pKioqLi9Xc3BwxprGxUUVFRUpOTlZ6erpWrFih7u7uyz8bAAAwIEQVKDU1NSotLdWePXtUVVWlrq4uzZo1Sx0dHc6Y5cuX6/XXX9eWLVtUU1OjU6dO6Z577nGO9/T0qKioSOfOndO7776rl156SRs3btRjjz3Wd2cFAAD6tThjjOntnU+fPq309HTV1NTojjvuUDAY1IgRI7Rp0ybde++9kqQPPvhAEyZMUG1traZPn67t27frzjvv1KlTp5SRkSFJ2rBhg1auXKnTp0/L5XJ95fOGQiF5vV4Fg0F5PJ7eTh+AhUy4R+/9rFQy4YuOu/XBZ5ToHnKVZgWgL0Tz+/uyrkEJBoOSpLS0NElSXV2durq6VFBQ4IwZP368cnJyVFtbK0mqra3VpEmTnDiRpMLCQoVCIR05cuSCz9PZ2alQKBSxAQCAgavXgRIOh7Vs2TLdfvvtmjhxoiQpEAjI5XIpNTU1YmxGRoYCgYAz5n/Hyfnj549dSGVlpbxer7NlZ2f3dtoAAKAf6HWglJaW6vDhw9q8eXNfzueCKioqFAwGne3kyZNX/DkBAEDsJPbmTmVlZdq2bZt2796tkSNHOvt9Pp/OnTun1tbWiFdRmpub5fP5nDH79u2LeLzzn/I5P+bz3G633G53b6YKAAD6oaheQTHGqKysTFu3btXOnTs1evToiONTpkxRUlKSqqurnX0NDQ1qbGyU3++XJPn9fh06dEgtLS3OmKqqKnk8HuXm5l7OuQAAgAEiqldQSktLtWnTJr322msaOnSoc82I1+vV4MGD5fV6tWjRIpWXlystLU0ej0cPP/yw/H6/pk+fLkmaNWuWcnNztWDBAq1du1aBQECrVq1SaWkpr5IAAABJUQbK+vXrJUkzZsyI2P/iiy/qwQcflCQ988wzio+PV3FxsTo7O1VYWKgXXnjBGZuQkKBt27Zp6dKl8vv9GjJkiEpKSvTEE09c3pkAAIAB47K+ByVW+B4UYODie1CAgeuqfQ8KAADAlUCgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6UQVKZWWlpk2bpqFDhyo9PV3z5s1TQ0NDxJgZM2YoLi4uYnvooYcixjQ2NqqoqEjJyclKT0/XihUr1N3dfflnAwAABoTEaAbX1NSotLRU06ZNU3d3t374wx9q1qxZOnr0qIYMGeKMW7x4sZ544gnndnJysvNzT0+PioqK5PP59O6776qpqUkLFy5UUlKSnnzyyT44JQAA0N9FFSg7duyIuL1x40alp6errq5Od9xxh7M/OTlZPp/vgo/x29/+VkePHtVbb72ljIwM3XLLLfrxj3+slStX6vHHH5fL5erFaQAAgIHksq5BCQaDkqS0tLSI/S+//LKGDx+uiRMnqqKiQp9++qlzrLa2VpMmTVJGRoazr7CwUKFQSEeOHLng83R2dioUCkVsAABg4IrqFZT/LRwOa9myZbr99ts1ceJEZ/93vvMdjRo1SllZWTp48KBWrlyphoYGvfLKK5KkQCAQESeSnNuBQOCCz1VZWak1a9b0dqoAAKCf6XWglJaW6vDhw3rnnXci9i9ZssT5edKkScrMzNTMmTN1/Phx3Xjjjb16roqKCpWXlzu3Q6GQsrOzezdxAABgvV69xVNWVqZt27bp7bff1siRIy86Nj8/X5J07NgxSZLP51Nzc3PEmPO3v+y6FbfbLY/HE7EBAICBK6pAMcaorKxMW7du1c6dOzV69OivvE99fb0kKTMzU5Lk9/t16NAhtbS0OGOqqqrk8XiUm5sbzXQAAMAAFdVbPKWlpdq0aZNee+01DR061LlmxOv1avDgwTp+/Lg2bdqkuXPnatiwYTp48KCWL1+uO+64Q3l5eZKkWbNmKTc3VwsWLNDatWsVCAS0atUqlZaWyu129/0ZAgCAfieqV1DWr1+vYDCoGTNmKDMz09l++ctfSpJcLpfeeustzZo1S+PHj9cjjzyi4uJivf76685jJCQkaNu2bUpISJDf79c//uM/auHChRHfmwIAAK5tUb2CYoy56PHs7GzV1NR85eOMGjVKb7zxRjRPDQAAriH8LR4AAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1kmM9QQADCzhcFjhcLjX9zfhnksa19PdIyV09/p54uLilJCQ0Ov7A7iyeAUFQJ969NFHNXjw4F5vQ4cOVU/3V4dHZmbmZT3Pgw8+eOUXA0Cv8QoKgD4VDofVfQmB8WVMfNwljevu7r6s5+npubRXagDEBoECwFrt3an6pCtLneHBcsWf1XVJAXkTP4n1tABcBQQKACud6crQ0fbb9WnYox6TpAR1a3BCSDclv6cM959jPT0AVxjXoACwTkePV38IFaqtZ7h6jEtSnHqUpPaeYTrYPkP/tys91lMEcIURKACsYhSv37X+H3WZQRc83m3c2hO8W13GfZVnBuBqIlAAWOirLpS9tAtpAfRfBAoAALAOgQIAAKxDoACwSpzC8nu3Kl4X/o6TePVoquc3Sow7d5VnBuBqiipQ1q9fr7y8PHk8Hnk8Hvn9fm3fvt05fvbsWZWWlmrYsGFKSUlRcXGxmpubIx6jsbFRRUVFSk5OVnp6ulasWHFZX7YEYODxJn6sqZ4dSo4P/v9QMYpXtwbHtylv6NsanvQXxcnEepoArqCovgdl5MiReuqppzR27FgZY/TSSy/p7rvv1oEDB3TzzTdr+fLl+s1vfqMtW7bI6/WqrKxM99xzj37/+99L+uybG4uKiuTz+fTuu++qqalJCxcuVFJSkp588skrcoIA+pewMXrt9w2Kj/+TQt1/VMu5UTobHiJX3F81wnVSrUmf/afnHN8ECwxoccaYy/pvSFpamp5++mnde++9GjFihDZt2qR7771XkvTBBx9owoQJqq2t1fTp07V9+3bdeeedOnXqlDIyMiRJGzZs0MqVK3X69Gm5XK5Les5QKCSv16sHH3zwku8D4OrYs2ePDh48GOtpfKUxY8boW9/6VqynAVxTzp07p40bNyoYDMrj8Vx0bK+/Sbanp0dbtmxRR0eH/H6/6urq1NXVpYKCAmfM+PHjlZOT4wRKbW2tJk2a5MSJJBUWFmrp0qU6cuSIbr311gs+V2dnpzo7O53boVBIkrRgwQKlpKT09hQAXAEdHR39IlBuuOEGLVq0KNbTAK4p7e3t2rhx4yWNjTpQDh06JL/fr7NnzyolJUVbt25Vbm6u6uvr5XK5lJqaGjE+IyNDgUBAkhQIBCLi5Pzx88e+TGVlpdasWfOF/VOnTv3KAgNwdfl8vlhP4ZIMGzZMt912W6ynAVxTzr/AcCmi/hTPuHHjVF9fr71792rp0qUqKSnR0aNHo32YqFRUVCgYDDrbyZMnr+jzAQCA2Ir6FRSXy6UxY8ZIkqZMmaL9+/frueee03333adz586ptbU14lWU5uZm539UPp9P+/bti3i885/yudj/utxut9xuvtYaAIBrxWV/D0o4HFZnZ6emTJmipKQkVVdXO8caGhrU2Ngov98vSfL7/Tp06JBaWlqcMVVVVfJ4PMrNzb3cqQAAgAEiqldQKioqNGfOHOXk5KitrU2bNm3Srl279Oabb8rr9WrRokUqLy9XWlqaPB6PHn74Yfn9fk2fPl2SNGvWLOXm5mrBggVau3atAoGAVq1apdLSUl4hAQAAjqgCpaWlRQsXLlRTU5O8Xq/y8vL05ptv6tvf/rYk6ZlnnlF8fLyKi4vV2dmpwsJCvfDCC879ExIStG3bNi1dulR+v19DhgxRSUmJnnjiib49KwAA0K9FFSg///nPL3p80KBBWrdundatW/elY0aNGqU33ngjmqcFAADXGP4WDwAAsA6BAgAArEOgAAAA6xAoAADAOr3+WzwAcCETJ07UvHnzYj2NrzR16tRYTwHARVz2XzOOhfN/zfhS/hoiAACwQzS/v3mLBwAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYB0CBQAAWIdAAQAA1iFQAACAdQgUAABgHQIFAABYh0ABAADWIVAAAIB1CBQAAGAdAgUAAFiHQAEAANYhUAAAgHUIFAAAYJ2oAmX9+vXKy8uTx+ORx+OR3+/X9u3bneMzZsxQXFxcxPbQQw9FPEZjY6OKioqUnJys9PR0rVixQt3d3X1zNgAAYEBIjGbwyJEj9dRTT2ns2LEyxuill17S3XffrQMHDujmm2+WJC1evFhPPPGEc5/k5GTn556eHhUVFcnn8+ndd99VU1OTFi5cqKSkJD355JN9dEoAAKC/izPGmMt5gLS0ND399NNatGiRZsyYoVtuuUXPPvvsBcdu375dd955p06dOqWMjAxJ0oYNG7Ry5UqdPn1aLpfrkp4zFArJ6/UqGAzK4/FczvQBAMBVEs3v715fg9LT06PNmzero6NDfr/f2f/yyy9r+PDhmjhxoioqKvTpp586x2prazVp0iQnTiSpsLBQoVBIR44c+dLn6uzsVCgUitgAAMDAFdVbPJJ06NAh+f1+nT17VikpKdq6datyc3MlSd/5znc0atQoZWVl6eDBg1q5cqUaGhr0yiuvSJICgUBEnEhybgcCgS99zsrKSq1ZsybaqQIAgH4q6kAZN26c6uvrFQwG9etf/1olJSWqqalRbm6ulixZ4oybNGmSMjMzNXPmTB0/flw33nhjrydZUVGh8vJy53YoFFJ2dnavHw8AANgt6rd4XC6XxowZoylTpqiyslKTJ0/Wc889d8Gx+fn5kqRjx45Jknw+n5qbmyPGnL/t8/m+9DndbrfzyaHzGwAAGLgu+3tQwuGwOjs7L3isvr5ekpSZmSlJ8vv9OnTokFpaWpwxVVVV8ng8zttEAAAAUb3FU1FRoTlz5ignJ0dtbW3atGmTdu3apTfffFPHjx/Xpk2bNHfuXA0bNkwHDx7U8uXLdccddygvL0+SNGvWLOXm5mrBggVau3atAoGAVq1apdLSUrnd7ityggAAoP+JKlBaWlq0cOFCNTU1yev1Ki8vT2+++aa+/e1v6+TJk3rrrbf07LPPqqOjQ9nZ2SouLtaqVauc+yckJGjbtm1aunSp/H6/hgwZopKSkojvTQEAALjs70GJBb4HBQCA/ueqfA8KAADAlUKgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACsQ6AAAADrECgAAMA6BAoAALAOgQIAAKyTGOsJ9IYxRpIUCoViPBMAAHCpzv/ePv97/GL6ZaC0tbVJkrKzs2M8EwAAEK22tjZ5vd6Ljokzl5IxlgmHw2poaFBubq5Onjwpj8cT6yn1W6FQSNnZ2axjH2At+w5r2TdYx77DWvYNY4za2tqUlZWl+PiLX2XSL19BiY+P19e+9jVJksfj4R9LH2Ad+w5r2XdYy77BOvYd1vLyfdUrJ+dxkSwAALAOgQIAAKzTbwPF7XZr9erVcrvdsZ5Kv8Y69h3Wsu+wln2Ddew7rOXV1y8vkgUAAANbv30FBQAADFwECgAAsA6BAgAArEOgAAAA6/TLQFm3bp2uv/56DRo0SPn5+dq3b1+sp2Sd3bt366677lJWVpbi4uL06quvRhw3xuixxx5TZmamBg8erIKCAn344YcRY86cOaP58+fL4/EoNTVVixYtUnt7+1U8i9irrKzUtGnTNHToUKWnp2vevHlqaGiIGHP27FmVlpZq2LBhSklJUXFxsZqbmyPGNDY2qqioSMnJyUpPT9eKFSvU3d19NU8lptavX6+8vDznS678fr+2b9/uHGcNe++pp55SXFycli1b5uxjPS/N448/rri4uIht/PjxznHWMcZMP7N582bjcrnMf/7nf5ojR46YxYsXm9TUVNPc3BzrqVnljTfeMP/yL/9iXnnlFSPJbN26NeL4U089Zbxer3n11VfNH//4R/P3f//3ZvTo0eavf/2rM2b27Nlm8uTJZs+ePeZ3v/udGTNmjHnggQeu8pnEVmFhoXnxxRfN4cOHTX19vZk7d67Jyckx7e3tzpiHHnrIZGdnm+rqavPee++Z6dOnm7/92791jnd3d5uJEyeagoICc+DAAfPGG2+Y4cOHm4qKilicUkz893//t/nNb35j/vSnP5mGhgbzwx/+0CQlJZnDhw8bY1jD3tq3b5+5/vrrTV5envne977n7Gc9L83q1avNzTffbJqampzt9OnTznHWMbb6XaDcdtttprS01Lnd09NjsrKyTGVlZQxnZbfPB0o4HDY+n888/fTTzr7W1lbjdrvNL37xC2OMMUePHjWSzP79+50x27dvN3FxceYvf/nLVZu7bVpaWowkU1NTY4z5bN2SkpLMli1bnDHvv/++kWRqa2uNMZ/FYnx8vAkEAs6Y9evXG4/HYzo7O6/uCVjkuuuuMz/72c9Yw15qa2szY8eONVVVVebv/u7vnEBhPS/d6tWrzeTJky94jHWMvX71Fs+5c+dUV1engoICZ198fLwKCgpUW1sbw5n1LydOnFAgEIhYR6/Xq/z8fGcda2trlZqaqqlTpzpjCgoKFB8fr7179171OdsiGAxKktLS0iRJdXV16urqiljL8ePHKycnJ2ItJ02apIyMDGdMYWGhQqGQjhw5chVnb4eenh5t3rxZHR0d8vv9rGEvlZaWqqioKGLdJP5NRuvDDz9UVlaWbrjhBs2fP1+NjY2SWEcb9Ks/Fvjxxx+rp6cn4h+DJGVkZOiDDz6I0az6n0AgIEkXXMfzxwKBgNLT0yOOJyYmKi0tzRlzrQmHw1q2bJluv/12TZw4UdJn6+RyuZSamhox9vNreaG1Pn/sWnHo0CH5/X6dPXtWKSkp2rp1q3Jzc1VfX88aRmnz5s36wx/+oP3793/hGP8mL11+fr42btyocePGqampSWvWrNE3vvENHT58mHW0QL8KFCCWSktLdfjwYb3zzjuxnkq/NG7cONXX1ysYDOrXv/61SkpKVFNTE+tp9TsnT57U9773PVVVVWnQoEGxnk6/NmfOHOfnvLw85efna9SoUfrVr36lwYMHx3BmkPrZp3iGDx+uhISEL1xF3dzcLJ/PF6NZ9T/n1+pi6+jz+dTS0hJxvLu7W2fOnLkm17qsrEzbtm3T22+/rZEjRzr7fT6fzp07p9bW1ojxn1/LC631+WPXCpfLpTFjxmjKlCmqrKzU5MmT9dxzz7GGUaqrq1NLS4v+5m/+RomJiUpMTFRNTY2ef/55JSYmKiMjg/XspdTUVN100006duwY/y4t0K8CxeVyacqUKaqurnb2hcNhVVdXy+/3x3Bm/cvo0aPl8/ki1jEUCmnv3r3OOvr9frW2tqqurs4Zs3PnToXDYeXn51/1OceKMUZlZWXaunWrdu7cqdGjR0ccnzJlipKSkiLWsqGhQY2NjRFreejQoYjgq6qqksfjUW5u7tU5EQuFw2F1dnayhlGaOXOmDh06pPr6emebOnWq5s+f7/zMevZOe3u7jh8/rszMTP5d2iDWV+lGa/PmzcbtdpuNGzeao0ePmiVLlpjU1NSIq6jx2RX+Bw4cMAcOHDCSzL//+7+bAwcOmD//+c/GmM8+Zpyammpee+01c/DgQXP33Xdf8GPGt956q9m7d6955513zNixY6+5jxkvXbrUeL1es2vXroiPIn766afOmIceesjk5OSYnTt3mvfee8/4/X7j9/ud4+c/ijhr1ixTX19vduzYYUaMGHFNfRTx0UcfNTU1NebEiRPm4MGD5tFHHzVxcXHmt7/9rTGGNbxc//tTPMawnpfqkUceMbt27TInTpwwv//9701BQYEZPny4aWlpMcawjrHW7wLFGGN++tOfmpycHONyucxtt91m9uzZE+spWeftt982kr6wlZSUGGM++6jxj370I5ORkWHcbreZOXOmaWhoiHiMTz75xDzwwAMmJSXFeDwe893vfte0tbXF4Gxi50JrKMm8+OKLzpi//vWv5p//+Z/NddddZ5KTk80//MM/mKampojH+Z//+R8zZ84cM3jwYDN8+HDzyCOPmK6urqt8NrHzT//0T2bUqFHG5XKZESNGmJkzZzpxYgxreLk+Hyis56W57777TGZmpnG5XOZrX/uaue+++8yxY8ec46xjbMUZY0xsXrsBAAC4sH51DQoAALg2ECgAAMA6BAoAALAOgQIAAKxDoAAAAOsQKAAAwDoECgAAsA6BAgAArEOgAAAA6xAoAADAOgQKAACwDoECAACs8/8AKRzrtl9y5yUAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, state_dim, n_actions):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.network = nn.Sequential(\n",
        "            nn.Linear(state_dim[0], 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "network = QNetwork(state_dim, n_actions)\n",
        "\n",
        "def get_action(state, epsilon=0):\n",
        "    state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
        "    q_values = network(state_tensor).detach().numpy()[0]\n",
        "    if np.random.rand() < epsilon:\n",
        "        # Выполняем случайное действие\n",
        "        return int(np.random.choice(n_actions))\n",
        "    # Действие с наибольшим Q(s,a)\n",
        "    return int(np.argmax(q_values))\n",
        "\n",
        "s = env.reset()\n",
        "assert network(torch.tensor(np.array([s] * 5), dtype=torch.float32)).shape == (5, n_actions), \"пожалуйста, убедитесь, что ваша модель отображает состояние s -> [Q(s,a0),..., Q(s, a_last)]\"\n",
        "\n",
        "assert isinstance(list(network.modules())[-1], nn.Linear),\"пожалуйста, убедитесь, что вы предсказываете q-значения без нелинейности\""
      ],
      "metadata": {
        "id": "QE-ZNz-bH_TX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AehcnSl3bVN",
        "outputId": "53638e1b-e8b7-4b32-f12e-8e661dc18abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e=0.0 tests passed\n",
            "e=0.1 tests passed\n",
            "e=0.5 tests passed\n",
            "e=1.0 tests passed\n"
          ]
        }
      ],
      "source": [
        "# Тест эпсилон-жадных исследований\n",
        "assert isinstance(get_action(s), int), \"верните только одно действие (integer)\"\n",
        "\n",
        "for eps in [0., 0.1, 0.5, 1.0]:\n",
        "    state_frequencies = np.bincount([get_action(s, epsilon=eps) for i in range(10000)], minlength=n_actions)\n",
        "    best_action = state_frequencies.argmax()\n",
        "    assert abs(state_frequencies[best_action] - 10000 * (1 - eps + eps / n_actions)) < 200\n",
        "    for other_action in range(n_actions):\n",
        "        if other_action != best_action:\n",
        "            assert abs(state_frequencies[other_action] - 10000 * (eps / n_actions)) < 200\n",
        "    print('e=%.1f tests passed' % eps)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации эпизодов с обучением агента\n",
        "def generate_session(env, t_max=1000, epsilon=0, train=False):\n",
        "    total_reward = 0\n",
        "    s = env.reset()\n",
        "    for t in range(t_max):\n",
        "        a = get_action(s, epsilon=epsilon)\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "       # Создадим тензоры  для  кортежа и специального индикатора окончания игры (is_done = True)\n",
        "        states_tensor = torch.tensor(s, dtype=torch.float32).unsqueeze(0)\n",
        "        actions_tensor = torch.tensor([a], dtype=torch.int64)\n",
        "        rewards_tensor = torch.tensor([r], dtype=torch.float32)\n",
        "        next_states_tensor = torch.tensor(next_s, dtype=torch.float32).unsqueeze(0)\n",
        "        is_done_tensor = torch.tensor([done], dtype=torch.bool)\n",
        "\n",
        "        # Задание q-значений для всех действий в текущем состоянии\n",
        "        predicted_qvalues = network(states_tensor)\n",
        "        #выборка q-значений для выбранных действий\n",
        "        predicted_qvalues_for_actions = torch.sum(predicted_qvalues * F.one_hot(actions_tensor, num_classes=n_actions), dim=1)\n",
        "\n",
        "        # Вычисление Q-значений для следующих состояний\n",
        "        predicted_next_qvalues = network(next_states_tensor)\n",
        "        next_state_values = torch.max(predicted_next_qvalues, dim=1)[0]\n",
        "\n",
        "        # Целевые Q-значения\n",
        "        target_qvalues_for_actions = rewards_tensor + gamma * next_state_values\n",
        "        target_qvalues_for_actions = torch.where(is_done_tensor, rewards_tensor, target_qvalues_for_actions)# выбор только награды для конечного состояния\n",
        "\n",
        "        # Потери\n",
        "        loss = torch.mean((predicted_qvalues_for_actions - target_qvalues_for_actions.detach()) ** 2)\n",
        "\n",
        "        # Оптимизация\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        total_reward += r\n",
        "        s = next_s\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        # Тесты\n",
        "        assert predicted_next_qvalues.data.dim() == 2, \"убедитесь, что вы предсказали значения q для всех действий в следующем состоянии\"\n",
        "        assert next_state_values.data.dim() == 1, \"убедитесь, что вы вычислили V (s') как максимум только по оси действий, а не по всем осям\"\n",
        "        assert target_qvalues_for_actions.data.dim() == 1, \"целевые Q-значения должны быть вектором\"\n",
        "\n",
        "    return total_reward"
      ],
      "metadata": {
        "id": "WssD46GhIKoR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оптимизатор и обучение\n",
        "gamma = 0.99\n",
        "optimizer = optim.Adam(network.parameters(), lr=1e-4)\n",
        "\n",
        "epsilon = 0.5\n",
        "for i in range(1000):\n",
        "    start_time = time.time()  # Замер времени начала эпохи\n",
        "    session_rewards = [generate_session(env, epsilon=epsilon, train=True) for _ in range(100)]\n",
        "    epoch_time = time.time() - start_time  # Вычисление времени выполнения эпохи\n",
        "    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\\ttime = {:.2f}s\".format(i, np.mean(session_rewards), epsilon, epoch_time))\n",
        "    epsilon *= 0.99\n",
        "    assert epsilon >= 1e-4, \" Убедитесь, что эпсилон всегда отличен от нуля во время обучения \"\n",
        "\n",
        "    if np.mean(session_rewards) > 300:\n",
        "        print(\"You Win!\")\n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWcYVrrTIPPG",
        "outputId": "81030922-7530-4f92-bbff-d9a714554fa3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch #0\tmean reward = 13.810\tepsilon = 0.500\ttime = 4.98s\n",
            "epoch #1\tmean reward = 14.450\tepsilon = 0.495\ttime = 3.24s\n",
            "epoch #2\tmean reward = 14.550\tepsilon = 0.490\ttime = 3.28s\n",
            "epoch #3\tmean reward = 12.900\tepsilon = 0.485\ttime = 3.56s\n",
            "epoch #4\tmean reward = 13.250\tepsilon = 0.480\ttime = 3.53s\n",
            "epoch #5\tmean reward = 14.990\tepsilon = 0.475\ttime = 3.67s\n",
            "epoch #6\tmean reward = 15.860\tepsilon = 0.471\ttime = 3.42s\n",
            "epoch #7\tmean reward = 16.200\tepsilon = 0.466\ttime = 4.65s\n",
            "epoch #8\tmean reward = 15.980\tepsilon = 0.461\ttime = 3.84s\n",
            "epoch #9\tmean reward = 18.810\tepsilon = 0.457\ttime = 4.11s\n",
            "epoch #10\tmean reward = 32.820\tepsilon = 0.452\ttime = 8.25s\n",
            "epoch #11\tmean reward = 31.140\tepsilon = 0.448\ttime = 9.02s\n",
            "epoch #12\tmean reward = 41.880\tepsilon = 0.443\ttime = 10.84s\n",
            "epoch #13\tmean reward = 44.080\tepsilon = 0.439\ttime = 10.38s\n",
            "epoch #14\tmean reward = 46.030\tepsilon = 0.434\ttime = 11.11s\n",
            "epoch #15\tmean reward = 55.600\tepsilon = 0.430\ttime = 13.41s\n",
            "epoch #16\tmean reward = 60.510\tepsilon = 0.426\ttime = 14.40s\n",
            "epoch #17\tmean reward = 69.930\tepsilon = 0.421\ttime = 17.18s\n",
            "epoch #18\tmean reward = 65.800\tepsilon = 0.417\ttime = 15.70s\n",
            "epoch #19\tmean reward = 87.780\tepsilon = 0.413\ttime = 22.50s\n",
            "epoch #20\tmean reward = 140.100\tepsilon = 0.409\ttime = 33.96s\n",
            "epoch #21\tmean reward = 148.200\tepsilon = 0.405\ttime = 37.06s\n",
            "epoch #22\tmean reward = 156.440\tepsilon = 0.401\ttime = 39.67s\n",
            "epoch #23\tmean reward = 183.460\tepsilon = 0.397\ttime = 45.36s\n",
            "epoch #24\tmean reward = 200.090\tepsilon = 0.393\ttime = 49.35s\n",
            "epoch #25\tmean reward = 188.580\tepsilon = 0.389\ttime = 48.10s\n",
            "epoch #26\tmean reward = 193.320\tepsilon = 0.385\ttime = 47.57s\n",
            "epoch #27\tmean reward = 161.880\tepsilon = 0.381\ttime = 39.75s\n",
            "epoch #28\tmean reward = 147.710\tepsilon = 0.377\ttime = 35.74s\n",
            "epoch #29\tmean reward = 151.950\tepsilon = 0.374\ttime = 39.30s\n",
            "epoch #30\tmean reward = 180.250\tepsilon = 0.370\ttime = 42.81s\n",
            "epoch #31\tmean reward = 209.750\tepsilon = 0.366\ttime = 50.64s\n",
            "epoch #32\tmean reward = 125.090\tepsilon = 0.362\ttime = 31.86s\n",
            "epoch #33\tmean reward = 160.980\tepsilon = 0.359\ttime = 39.59s\n",
            "epoch #34\tmean reward = 312.030\tepsilon = 0.355\ttime = 77.24s\n",
            "You Win!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Реализация на Tensorflow"
      ],
      "metadata": {
        "id": "F4oSeou5I57O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "env = gym.make(\"CartPole-v1\").env\n",
        "env.reset()\n",
        "n_actions = env.action_space.n\n",
        "state_dim = env.observation_space.shape\n",
        "plt.imshow(env.render(\"rgb_array\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "id": "d6del3Tu90Qx",
        "outputId": "2cbcbeb0-46ed-4420-88a5-ec21c7f0d0b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:43: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n",
            "See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n",
            "  deprecation(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7e5079423ac0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class QNetwork(tf.keras.Model):\n",
        "    def __init__(self, state_dim, n_actions):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.network = tf.keras.Sequential([\n",
        "            layers.Dense(64, activation='relu', input_shape=state_dim),\n",
        "            layers.Dense(128, activation='relu'),\n",
        "            layers.Dense(n_actions)\n",
        "        ])\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "network = QNetwork(state_dim, n_actions)\n",
        "\n",
        "def get_action(state, epsilon=0):\n",
        "    state_tensor = tf.convert_to_tensor(state, dtype=tf.float32)[None, :]\n",
        "    q_values = network(state_tensor).numpy()[0]\n",
        "    if np.random.rand() < epsilon:\n",
        "        # Выполняем случайное действие\n",
        "        return int(np.random.choice(n_actions))\n",
        "    # Действие с наибольшим Q(s,a)\n",
        "    return int(np.argmax(q_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4VagvNVeY55",
        "outputId": "33e52e96-699e-4759-9e2c-d90066a8bced"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = env.reset()\n",
        "assert network(tf.convert_to_tensor(np.array([s] * 5), dtype=tf.float32)).shape == (5, n_actions), \"пожалуйста, убедитесь, что ваша модель отображает состояние s -> [Q(s,a0),..., Q(s, a_last)]\"\n",
        "\n",
        "# Проверка эпсилон-жадных исследований\n",
        "assert isinstance(get_action(s), int), \"верните только одно действие (integer)\"\n",
        "\n",
        "for eps in [0., 0.1, 0.5, 1.0]:\n",
        "    state_frequencies = np.bincount([get_action(s, epsilon=eps) for i in range(10000)], minlength=n_actions)\n",
        "    best_action = state_frequencies.argmax()\n",
        "    assert abs(state_frequencies[best_action] - 10000 * (1 - eps + eps / n_actions)) < 200\n",
        "    for other_action in range(n_actions):\n",
        "        if other_action != best_action:\n",
        "            assert abs(state_frequencies[other_action] - 10000 * (eps / n_actions)) < 200\n",
        "    print('e=%.1f tests passed' % eps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQQiS4DnbQrD",
        "outputId": "32548620-a79e-4716-eb12-0a4e2186813c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "e=0.0 tests passed\n",
            "e=0.1 tests passed\n",
            "e=0.5 tests passed\n",
            "e=1.0 tests passed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция для генерации эпизодов с обучением агента\n",
        "def generate_session(env, t_max=1000, epsilon=0, train=False):\n",
        "    total_reward = 0\n",
        "    s = env.reset()\n",
        "    for t in range(t_max):\n",
        "        a = get_action(s, epsilon=epsilon)\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "\n",
        "        # Создадим тензоры для кортежа и специального индикатора окончания игры (is_done = True)\n",
        "        states_tensor = tf.convert_to_tensor(s, dtype=tf.float32)[None, :]\n",
        "        actions_tensor = tf.convert_to_tensor([a], dtype=tf.int64)\n",
        "        rewards_tensor = tf.convert_to_tensor([r], dtype=tf.float32)\n",
        "        next_states_tensor = tf.convert_to_tensor(next_s, dtype=tf.float32)[None, :]\n",
        "        is_done_tensor = tf.convert_to_tensor([done], dtype=tf.bool)\n",
        "\n",
        "        if train:\n",
        "            with tf.GradientTape() as tape:\n",
        "                # Задание q-значений для всех действий в текущем состоянии\n",
        "                predicted_qvalues = network(states_tensor)\n",
        "                # Выборка q-значений для выбранных действий\n",
        "                predicted_qvalues_for_actions = tf.reduce_sum(\n",
        "                    predicted_qvalues * tf.one_hot(actions_tensor, n_actions), axis=1\n",
        "                )\n",
        "\n",
        "                # Вычисление Q-значений для следующих состояний\n",
        "                predicted_next_qvalues = network(next_states_tensor)\n",
        "                next_state_values = tf.reduce_max(predicted_next_qvalues, axis=1)\n",
        "\n",
        "                # Целевые Q-значения\n",
        "                target_qvalues_for_actions = rewards_tensor + gamma * next_state_values\n",
        "                target_qvalues_for_actions = tf.where(\n",
        "                    is_done_tensor, rewards_tensor, target_qvalues_for_actions\n",
        "                )\n",
        "\n",
        "                # Потери\n",
        "                loss = tf.reduce_mean((predicted_qvalues_for_actions - target_qvalues_for_actions) ** 2)\n",
        "\n",
        "            # Оптимизация\n",
        "            grads = tape.gradient(loss, network.trainable_variables)\n",
        "            optimizer.apply_gradients(zip(grads, network.trainable_variables))\n",
        "\n",
        "        total_reward += r\n",
        "        s = next_s\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "        # Тесты\n",
        "        assert predicted_qvalues.shape[1] == n_actions, \\\n",
        "            \"Убедитесь, что вы предсказали значения Q для всех действий в следующем состоянии\"\n",
        "        assert next_state_values.shape[0] == 1, \\\n",
        "            \"Убедитесь, что вы вычислили V(s') как максимум только по оси действий, а не по всем осям\"\n",
        "        assert target_qvalues_for_actions.shape[0] == 1, \\\n",
        "            \"Целевые Q-значения должны быть вектором\"\n",
        "\n",
        "    return total_reward"
      ],
      "metadata": {
        "id": "EKNG9_7SWRpC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Оптимизатор и обучение\n",
        "gamma = 0.99\n",
        "optimizer = tf.optimizers.Adam(learning_rate=1e-4)\n",
        "\n",
        "epsilon = 0.5\n",
        "for i in range(1000):\n",
        "    start_time = time.time()  # Замер времени начала эпохи\n",
        "    session_rewards = [generate_session(env, epsilon=epsilon, train=True) for _ in range(100)]\n",
        "    epoch_time = time.time() - start_time  # Вычисление времени выполнения эпохи\n",
        "    print(\"epoch #{}\\tmean reward = {:.3f}\\tepsilon = {:.3f}\\ttime = {:.2f}s\".format(i, np.mean(session_rewards), epsilon, epoch_time))\n",
        "    epsilon *= 0.99\n",
        "    assert epsilon >= 1e-4, \" Убедитесь, что эпсилон всегда отличен от нуля во время обучения \"\n",
        "\n",
        "    if np.mean(session_rewards) > 300:\n",
        "        print(\"You Win!\")\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-PB0RMA8O8n",
        "outputId": "2cd3688b-9146-4f07-daf5-369b6cbf5803"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:241: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch #0\tmean reward = 24.940\tepsilon = 0.500\ttime = 138.43s\n",
            "epoch #1\tmean reward = 23.380\tepsilon = 0.495\ttime = 134.45s\n",
            "epoch #2\tmean reward = 20.020\tepsilon = 0.490\ttime = 115.30s\n",
            "epoch #3\tmean reward = 23.040\tepsilon = 0.485\ttime = 129.99s\n",
            "epoch #4\tmean reward = 24.870\tepsilon = 0.480\ttime = 140.32s\n",
            "epoch #5\tmean reward = 29.520\tepsilon = 0.475\ttime = 163.14s\n",
            "epoch #6\tmean reward = 37.260\tepsilon = 0.471\ttime = 208.53s\n",
            "epoch #7\tmean reward = 33.330\tepsilon = 0.466\ttime = 198.03s\n",
            "epoch #8\tmean reward = 29.790\tepsilon = 0.461\ttime = 174.43s\n",
            "epoch #9\tmean reward = 32.210\tepsilon = 0.457\ttime = 187.00s\n",
            "epoch #10\tmean reward = 40.190\tepsilon = 0.452\ttime = 233.34s\n",
            "epoch #11\tmean reward = 35.460\tepsilon = 0.448\ttime = 207.84s\n",
            "epoch #12\tmean reward = 35.680\tepsilon = 0.443\ttime = 216.89s\n",
            "epoch #13\tmean reward = 42.390\tepsilon = 0.439\ttime = 239.67s\n",
            "epoch #14\tmean reward = 50.070\tepsilon = 0.434\ttime = 282.19s\n",
            "epoch #15\tmean reward = 47.280\tepsilon = 0.430\ttime = 264.26s\n",
            "epoch #16\tmean reward = 44.320\tepsilon = 0.426\ttime = 244.77s\n",
            "epoch #17\tmean reward = 43.840\tepsilon = 0.421\ttime = 244.17s\n",
            "epoch #18\tmean reward = 45.540\tepsilon = 0.417\ttime = 256.39s\n",
            "epoch #19\tmean reward = 43.190\tepsilon = 0.413\ttime = 254.16s\n",
            "epoch #20\tmean reward = 45.390\tepsilon = 0.409\ttime = 259.66s\n",
            "epoch #21\tmean reward = 49.130\tepsilon = 0.405\ttime = 292.90s\n",
            "epoch #22\tmean reward = 47.580\tepsilon = 0.401\ttime = 280.81s\n",
            "epoch #23\tmean reward = 54.110\tepsilon = 0.397\ttime = 309.56s\n",
            "epoch #24\tmean reward = 67.430\tepsilon = 0.393\ttime = 386.41s\n",
            "epoch #25\tmean reward = 60.510\tepsilon = 0.389\ttime = 348.89s\n",
            "epoch #26\tmean reward = 62.530\tepsilon = 0.385\ttime = 361.94s\n",
            "epoch #27\tmean reward = 70.220\tepsilon = 0.381\ttime = 407.25s\n",
            "epoch #28\tmean reward = 72.360\tepsilon = 0.377\ttime = 420.77s\n",
            "epoch #29\tmean reward = 79.140\tepsilon = 0.374\ttime = 458.13s\n",
            "epoch #30\tmean reward = 80.440\tepsilon = 0.370\ttime = 464.62s\n",
            "epoch #31\tmean reward = 82.770\tepsilon = 0.366\ttime = 467.11s\n",
            "epoch #32\tmean reward = 71.230\tepsilon = 0.362\ttime = 397.37s\n",
            "epoch #33\tmean reward = 81.090\tepsilon = 0.359\ttime = 453.39s\n",
            "epoch #34\tmean reward = 83.210\tepsilon = 0.355\ttime = 451.56s\n",
            "epoch #35\tmean reward = 102.510\tepsilon = 0.352\ttime = 569.27s\n",
            "epoch #36\tmean reward = 94.790\tepsilon = 0.348\ttime = 520.31s\n",
            "epoch #37\tmean reward = 84.790\tepsilon = 0.345\ttime = 474.27s\n",
            "epoch #38\tmean reward = 113.000\tepsilon = 0.341\ttime = 641.70s\n",
            "epoch #39\tmean reward = 106.730\tepsilon = 0.338\ttime = 602.20s\n",
            "epoch #40\tmean reward = 101.580\tepsilon = 0.334\ttime = 585.37s\n",
            "epoch #41\tmean reward = 125.830\tepsilon = 0.331\ttime = 683.45s\n",
            "epoch #42\tmean reward = 140.100\tepsilon = 0.328\ttime = 771.10s\n",
            "epoch #43\tmean reward = 150.050\tepsilon = 0.325\ttime = 813.63s\n",
            "epoch #44\tmean reward = 131.990\tepsilon = 0.321\ttime = 753.13s\n",
            "epoch #45\tmean reward = 144.160\tepsilon = 0.318\ttime = 817.83s\n",
            "epoch #46\tmean reward = 119.920\tepsilon = 0.315\ttime = 673.54s\n",
            "epoch #47\tmean reward = 140.480\tepsilon = 0.312\ttime = 806.04s\n",
            "epoch #48\tmean reward = 147.750\tepsilon = 0.309\ttime = 819.39s\n",
            "epoch #49\tmean reward = 150.620\tepsilon = 0.306\ttime = 830.34s\n",
            "epoch #50\tmean reward = 166.160\tepsilon = 0.303\ttime = 940.36s\n",
            "epoch #51\tmean reward = 150.260\tepsilon = 0.299\ttime = 811.15s\n",
            "epoch #52\tmean reward = 166.710\tepsilon = 0.296\ttime = 921.72s\n",
            "epoch #53\tmean reward = 166.750\tepsilon = 0.294\ttime = 921.53s\n",
            "epoch #54\tmean reward = 144.040\tepsilon = 0.291\ttime = 778.80s\n",
            "epoch #55\tmean reward = 175.010\tepsilon = 0.288\ttime = 937.47s\n",
            "epoch #56\tmean reward = 142.640\tepsilon = 0.285\ttime = 734.22s\n",
            "epoch #57\tmean reward = 124.070\tepsilon = 0.282\ttime = 645.88s\n",
            "epoch #58\tmean reward = 157.090\tepsilon = 0.279\ttime = 836.30s\n",
            "epoch #59\tmean reward = 141.630\tepsilon = 0.276\ttime = 741.37s\n",
            "epoch #60\tmean reward = 144.400\tepsilon = 0.274\ttime = 752.31s\n",
            "epoch #61\tmean reward = 184.810\tepsilon = 0.271\ttime = 996.25s\n",
            "epoch #62\tmean reward = 168.310\tepsilon = 0.268\ttime = 887.61s\n",
            "epoch #63\tmean reward = 179.280\tepsilon = 0.265\ttime = 941.82s\n",
            "epoch #64\tmean reward = 241.950\tepsilon = 0.263\ttime = 1265.62s\n",
            "epoch #65\tmean reward = 207.430\tepsilon = 0.260\ttime = 1139.72s\n",
            "epoch #66\tmean reward = 196.020\tepsilon = 0.258\ttime = 1031.13s\n",
            "epoch #67\tmean reward = 192.250\tepsilon = 0.255\ttime = 1057.26s\n",
            "epoch #68\tmean reward = 196.270\tepsilon = 0.252\ttime = 1050.58s\n",
            "epoch #69\tmean reward = 186.770\tepsilon = 0.250\ttime = 994.61s\n",
            "epoch #70\tmean reward = 234.440\tepsilon = 0.247\ttime = 1226.53s\n",
            "epoch #71\tmean reward = 208.030\tepsilon = 0.245\ttime = 1094.53s\n"
          ]
        }
      ]
    }
  ]
}